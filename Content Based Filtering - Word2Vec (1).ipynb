{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe590354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import warnings\n",
    "import ast\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import unidecode\n",
    "from nltk import WordNetLemmatizer\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5d7e5",
   "metadata": {},
   "source": [
    "# Content Based Recommender\n",
    "In a content-based recommendation system, the objective is to discern the user's preferences and construct a set of features that the algorithm can utilize to suggest previously unseen recipes that align with the user's unique taste profile.\n",
    "\n",
    "In our recommendation system, we will be using ingredients as the features to construct the item profile. We will not be constructing user profiling as we do not have an implicit feedback that we can use. This information includes number of clicks/view on a recipe, view time of recipe, etc.\n",
    "\n",
    "To develop our recommender system, we must transform each ingredient into a vector, followed by the aggregation of these vectors within the recipe. This aggregation process involves calculating the average of these vectors, resulting in the creation of a comprehensive document vector.\n",
    "\n",
    "In our project, our objective is to generate recipe recommendations based on a user's input list of ingredients. To achieve this, we will recommend recipes to the user by evaluating the vectorized representations of the input ingredients in relation to the mean aggregation of a list of potential ingredients. This comparison will be facilitated by assessing the recipes that exhibit the closest proximity in vector space.\n",
    "\n",
    "Furthermore, we will employ the Jaccard Similarity score to enhance our recipe recommendations based on user-input ingredients. The Jaccard similarity metric quantifies similarity by considering the shared and distinct values between sets. In this approach, as the number of input ingredients found in a recipe increases, so does the Jaccard similarity score, leading to a more robust recommendation for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097edf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import recipe dataset\n",
    "df = pd.read_csv('Cleaned_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f059ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>RecipeName</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>...</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_raw_str</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>AggregatedRating</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>Carrot Cake II</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>['Vegetable' 'Weeknight' 'Oven' '&lt; 4 Hours']</td>\n",
       "      <td>1173.5</td>\n",
       "      <td>69.8</td>\n",
       "      <td>19.4</td>\n",
       "      <td>154.7</td>\n",
       "      <td>720.2</td>\n",
       "      <td>...</td>\n",
       "      <td>['carrot', 'egg', 'sugar', 'all purpose flour'...</td>\n",
       "      <td>[\"1   lb    carrot, freshly grated \",\"4   larg...</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>Commissary Carrot Cake</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>['Vegetable' 'Low Protein' 'Weeknight' 'For La...</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>67.4</td>\n",
       "      <td>28.3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>401.4</td>\n",
       "      <td>...</td>\n",
       "      <td>['sugar', 'flour', 'salt', 'heavy cream', 'uns...</td>\n",
       "      <td>[\"1 1/2  cups    sugar\",\"1/4  cup    flour\",\"3...</td>\n",
       "      <td>240</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RecipeId              RecipeName RecipeCategory  \\\n",
       "0           0       120          Carrot Cake II        Dessert   \n",
       "1           1       122  Commissary Carrot Cake        Dessert   \n",
       "\n",
       "                                            Keywords  Calories  FatContent  \\\n",
       "0       ['Vegetable' 'Weeknight' 'Oven' '< 4 Hours']    1173.5        69.8   \n",
       "1  ['Vegetable' 'Low Protein' 'Weeknight' 'For La...    1011.8        67.4   \n",
       "\n",
       "   SaturatedFatContent  CholesterolContent  SodiumContent  ...  \\\n",
       "0                 19.4               154.7          720.2  ...   \n",
       "1                 28.3               146.0          401.4  ...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ['carrot', 'egg', 'sugar', 'all purpose flour'...   \n",
       "1  ['sugar', 'flour', 'salt', 'heavy cream', 'uns...   \n",
       "\n",
       "                                 ingredients_raw_str  minutes  n_steps  \\\n",
       "0  [\"1   lb    carrot, freshly grated \",\"4   larg...       75       11   \n",
       "1  [\"1 1/2  cups    sugar\",\"1/4  cup    flour\",\"3...      240       34   \n",
       "\n",
       "  n_ingredients  AggregatedRating  ReviewCount  year month  day_of_week  \n",
       "0            13              4.25          4.0  1999     9            6  \n",
       "1            18              3.00          1.0  1999     9            3  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844506e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e30ad",
   "metadata": {},
   "source": [
    "## Preprocessing ingredients\n",
    "Before we run out model, we need to ensure that the ingredients column is cleaned up before we run our Word2Vec algorithm. We will build a function to clean the ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c18ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change String to List\n",
    "df['ingredients'] = df['ingredients'].apply(lambda s: list(ast.literal_eval(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2713e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingredient preprocess function\n",
    "def ingredient_preprocess(ingredients):\n",
    "        \n",
    "    ingrd_list = []\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    num_pattern = r'[0-9]'\n",
    "    non_alphabet = r'[\\W_]'\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in ingredients:\n",
    "        #remove punctuations\n",
    "        items = i.translate(translator)\n",
    "        \n",
    "        #Making all characters lowercase\n",
    "        items = i.lower()\n",
    "        \n",
    "        #remove any numbers\n",
    "        items = re.sub(num_pattern, ' ', items)\n",
    "        \n",
    "        #remove accents\n",
    "        items = unidecode.unidecode(items)\n",
    "        \n",
    "        #remove any non-alphabet characters\n",
    "        items = re.sub(non_alphabet, ' ', items)\n",
    "        \n",
    "        #Lemmatize words\n",
    "        items = lemmatizer.lemmatize(items)\n",
    "        \n",
    "        ingrd_list.append(items)\n",
    "    return ingrd_list\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31006301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up output of ingredients from recommendation\n",
    "def ingredient_parser_final(ingredient):\n",
    "    \"\"\"\n",
    "    cleanup ingredients output\n",
    "    \"\"\"\n",
    "    if isinstance(ingredient, list):\n",
    "        ingredients = ingredient\n",
    "    else:\n",
    "        ingredients = ast.literal_eval(ingredient)\n",
    "\n",
    "    ingredients = \",\".join(ingredients)\n",
    "    ingredients = unidecode.unidecode(ingredients)\n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4aaec1",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1bcdc",
   "metadata": {},
   "source": [
    "There are two main training algorithms for Word2Vec gensim model. One is continous bag of words(CBOW) and the other is skip-gram. <br>\n",
    "\n",
    "CBOW method uses context and the surrounding words to predict the middle word. Skip-gram method uses a word to predict a target context. <br>\n",
    "\n",
    "We will be using the CBOW method for our Word2Vec model as it is a more efficient method and works well with more frequent words, which is the case for our ingredients column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4857d",
   "metadata": {},
   "source": [
    "Since the CBOW method uses surrounding words to predict the middle word, the structure of the list is very important in the prediction. To standardize and ensure that we have the best accuracy in the prediction, we need to sort the ingredients list by alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2cbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To sort ingredients list in alphabetical order\n",
    "def get_and_sort_corpus(data):\n",
    "    corpus_sorted = []\n",
    "    for doc in data['ingredients'].values:\n",
    "        doc.sort()\n",
    "        corpus_sorted.append(doc)\n",
    "    return corpus_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59faae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_corpus = get_and_sort_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db095c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Word2Vec model\n",
    "total_lengths = [len(ingredients) for ingredients in df['ingredients']]\n",
    "avg_len = sum(total_lengths) / len(total_lengths)\n",
    "\n",
    "model_Word2Vec = Word2Vec(ingredients_corpus, \n",
    "                          sg = 0, \n",
    "                          workers = 3, \n",
    "                          min_count = 1, \n",
    "                          window = avg_len, \n",
    "                          vector_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f6fb7",
   "metadata": {},
   "source": [
    "**Parameters** <br>\n",
    "sg: CBOW (0) or skip gram (1) <br>\n",
    "workers: number of patritions during training (default is 3) <br>\n",
    "min_count = minimum count of words to consider when training the model <br>\n",
    "window: maximum distance between target word and words around (sliding window length) <br>\n",
    "vector size: dimensionality of word vectors. Smaller vector size captures more general word relationship, larger vector size captuer more nuanced and specific words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "062de7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = {word: model_Word2Vec.wv[word] for word in model_Word2Vec.wv.key_to_index}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80427bd",
   "metadata": {},
   "source": [
    "Now that we have the word vectors created, we will now created the mean embedding vector for the recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbdd6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    \n",
    "    def __init__(self, model_Word2Vec):\n",
    "        self.model_Word2Vec = model_Word2Vec\n",
    "        self.vector_size = model_Word2Vec.wv.vector_size\n",
    "    \n",
    "    def transform(self, docs):\n",
    "        doc_word_vector = self.doc_average_list(docs)\n",
    "        return doc_word_vector\n",
    "    \n",
    "    def doc_average(self, doc):\n",
    "        \"\"\"\n",
    "        Compute average word vector for a recipe's ingredient\n",
    "        \n",
    "        :param doc: list of ingredients\n",
    "        :return\n",
    "            mean: float of average word vectors\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        mean = []\n",
    "        for word in doc:\n",
    "            if word in self.model_Word2Vec.wv.index_to_key:\n",
    "                mean.append(self.model_Word2Vec.wv.get_vector(word))\n",
    "                \n",
    "        if not mean: #empty words\n",
    "            #If text empty, return vector of zeros\n",
    "            return np.zeros(self.vector_size)\n",
    "        else:\n",
    "            mean = np.array(mean).mean(axis = 0)\n",
    "            return mean\n",
    "        \n",
    "    def doc_average_list(self, docs):\n",
    "        \"\"\"\n",
    "        Compute average word vector for multiple docs (doc has been tokenized)\n",
    "        \n",
    "        :param docs: list of recipes in list of tokens\n",
    "        :return\n",
    "            array of average word vector\n",
    "        \n",
    "        \"\"\"\n",
    "        return np.vstack([self.doc_average(doc) for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c40cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec_tr = MeanEmbeddingVectorizer(model_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c050bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec = mean_vec_tr.transform(ingredients_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094c5b8",
   "metadata": {},
   "source": [
    "### Cosine similarity recommendation\n",
    "Now we can build our cosine similarity recommendation system. We will have a recommendation funciton that will recommend top-N based on the highest cosine similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "070a890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Recommendation\n",
    "def get_recommendations(N, scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\",\"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "def get_recs_cosine(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    \"\"\"\n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df\n",
    "    # create corpus\n",
    "    corpus = get_and_sort_corpus(data)\n",
    "\n",
    "    # get average embdeddings for each document\n",
    "    mean_vec_tr = MeanEmbeddingVectorizer(model_Word2Vec)\n",
    "    doc_vec = mean_vec_tr.transform(corpus)\n",
    "    doc_vec = [doc.reshape(1, -1) for doc in doc_vec]\n",
    "    assert len(doc_vec) == len(corpus)\n",
    "    \n",
    "\n",
    "    # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input = ingredient_preprocess(input)\n",
    "    # get embeddings for ingredient doc\n",
    "    input_embedding = mean_vec_tr.transform([input])[0].reshape(1, -1)\n",
    "   \n",
    "    # get cosine similarity between input embedding and all the document embeddings\n",
    "    cos_sim = map(lambda x: cosine_similarity(input_embedding, x)[0][0], doc_vec)\n",
    "    scores = list(cos_sim)\n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f82a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              recipe  \\\n",
      "0  Chicken or Beef Flavored Brown Rice Using Pamp...   \n",
      "1            Nif's Butterflied Grilled Whole Chicken   \n",
      "2                          Amanda's Chicken and Rice   \n",
      "3   Buffalo Chicken Deviled Eggs (Aka Buffalo Horns)   \n",
      "4    Too Tired, &amp; Broke, Yellow Rice and Chicken   \n",
      "5                             No Noodle Chicken Soup   \n",
      "6                                         Cup A Rice   \n",
      "7                      Easiest Chicken Recipe of All   \n",
      "8                                     Phoney Abalone   \n",
      "9              Quick Chicken, Rice &amp; Veggie Soup   \n",
      "\n",
      "                                         ingredients               score  \\\n",
      "0               [brown rice, butter, chicken, water]  0.7459433078765869   \n",
      "1                      [chicken, dry rub seasonings]   0.743054986000061   \n",
      "2                      [butter, chicken, white rice]  0.7408969402313232   \n",
      "3  [butter, celery, chicken, cooked chicken, hard...   0.732718825340271   \n",
      "4                             [chicken, yellow rice]  0.7293022871017456   \n",
      "5           [carrot, chicken breasts, chicken broth]  0.7264828085899353   \n",
      "6  [chicken breasts, cooked rice, cream of chicke...  0.7243309617042542   \n",
      "7                                    [chicken, salt]  0.7176465392112732   \n",
      "8  [chicken, chicken breasts, cracker crumbs, egg...  0.7148915529251099   \n",
      "9  [butter, carrot, celery, chicken, chicken, chi...  0.7114368677139282   \n",
      "\n",
      "  rating  \n",
      "0    5.0  \n",
      "1    4.0  \n",
      "2    4.0  \n",
      "3    5.0  \n",
      "4    4.0  \n",
      "5    5.0  \n",
      "6   4.33  \n",
      "7    3.0  \n",
      "8    5.0  \n",
      "9    4.5  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "rec_cosine = get_recs_cosine(input_ingredient, N=10)\n",
    "print(rec_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5435fe5",
   "metadata": {},
   "source": [
    "### Jaccard similarity\n",
    "We will now build the recommendation system based on the highest jaccard similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b022721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(N, scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\", \"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def get_recs_jaccard(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    \"\"\"\n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df[df['n_ingredients'] >5]\n",
    "    \n",
    "     # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input_ingredient = ingredient_preprocess(input)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        intersection = len(set(input_ingredient).intersection(set(row['ingredients'])))\n",
    "        union = len(set(input_ingredient).union(set(row['ingredients'])))\n",
    "        jaccard_similarity = intersection / union\n",
    "        scores.append(jaccard_similarity)\n",
    "        \n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17d7b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   recipe  \\\n",
      "0                   Lemon-Buttered Salmon   \n",
      "1                   Lemony Salmon Patties   \n",
      "2                        Shepherd's Pie V   \n",
      "3                        Spicy Fish Cakes   \n",
      "4                          Karo Pecan Pie   \n",
      "5                Puffy Parmesan Pinwheels   \n",
      "6                     Ricotta Spinach Pie   \n",
      "7  Baked Chicken with Garlic and Rosemary   \n",
      "8                Aussie Tuna Summer Salad   \n",
      "9      Baked Brie with Caramelized Pecans   \n",
      "\n",
      "                                         ingredients score rating  \n",
      "0  [butter, herb seasoned salt, lemon juice, papr...   0.1    4.6  \n",
      "1  [all purpose flour, butter, cayenne pepper, eg...   0.1   4.42  \n",
      "2  [beef, cream style corn, mashed potatoes, onio...   0.1    4.5  \n",
      "3  [butter, creole seasoning, egg, fish fillets, ...   0.1    3.0  \n",
      "4  [butter, dark karo syrup, egg, pecan, salt, su...   0.1    4.0  \n",
      "5  [black olives, hungarian paprika, parmesan che...   0.1    5.0  \n",
      "6  [butter, butter, egg yolks, fresh basil, fresh...   0.1    3.0  \n",
      "7  [chicken portions, chicken stock powder, fresh...   0.1    4.5  \n",
      "8  [avocado, balsamic vinegar, basil, button mush...   0.1    4.6  \n",
      "9  [brie cheese, brown sugar, butter, pecan, sour...   0.1    2.5  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "rec_jaccard = get_recs_jaccard(input_ingredient, N=10)\n",
    "print(rec_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431e376",
   "metadata": {},
   "source": [
    "### Combination of cosine and Jaccard\n",
    "We will not test the the recommendation with a mix of the cosine and Jaccard similarity score and evaluate what results are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b26f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(N, combine_scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(combine_scores)), key=lambda i: combine_scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\", \"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{combine_scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def get_recs(ingredients, cosine_weight, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    :param cosine_weight: weight applied to cosine similarity score; other weight used is the jaccard similarity score\n",
    "    \"\"\"\n",
    "    assert cosine_weight <= 1\n",
    "    \n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df\n",
    "    # create corpus\n",
    "    corpus = get_and_sort_corpus(data)\n",
    "\n",
    "    # get average embdeddings for each document\n",
    "    mean_vec_tr = MeanEmbeddingVectorizer(model_Word2Vec)\n",
    "    doc_vec = mean_vec_tr.transform(corpus)\n",
    "    doc_vec = [doc.reshape(1, -1) for doc in doc_vec]\n",
    "    assert len(doc_vec) == len(corpus)\n",
    "    \n",
    "     # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input = ingredient_preprocess(input)\n",
    "    # get embeddings for ingredient doc\n",
    "    input_embedding = mean_vec_tr.transform([input])[0].reshape(1, -1)\n",
    "    input_ingredient = input\n",
    "    \n",
    "   \n",
    "    # get cosine similarity between input embedding and all the document embeddings\n",
    "    cos_sim = map(lambda x: cosine_similarity(input_embedding, x)[0][0], doc_vec)\n",
    "    cosine_scores = list(cos_sim)\n",
    "    \n",
    "    jaccard_scores = []\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        intersection = len(set(input_ingredient).intersection(set(row['ingredients'])))\n",
    "        union = len(set(input_ingredient).union(set(row['ingredients'])))\n",
    "        jaccard_similarity = intersection / union\n",
    "        jaccard_scores.append(jaccard_similarity)\n",
    "        \n",
    "    jaccard_weight = 1 - cosine_weight    \n",
    "        \n",
    "    combine_scores = (np.array(cosine_scores) * cosine_weight) + (np.array(jaccard_scores) * jaccard_weight)\n",
    "        \n",
    "        \n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, combine_scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a9b72da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              recipe  \\\n",
      "0            Nif's Butterflied Grilled Whole Chicken   \n",
      "1    Too Tired, &amp; Broke, Yellow Rice and Chicken   \n",
      "2                      Easiest Chicken Recipe of All   \n",
      "3                  The Easiest Chicken in the World!   \n",
      "4                             Barbecued Oven Chicken   \n",
      "5                          Amanda's Chicken and Rice   \n",
      "6                     Crock Pot Tasty Tomato Chicken   \n",
      "7                           Rick's Crock Pot Chicken   \n",
      "8                              Beerinthebutt chicken   \n",
      "9  Chicken or Beef Flavored Brown Rice Using Pamp...   \n",
      "\n",
      "                            ingredients                score rating  \n",
      "0         [chicken, dry rub seasonings]  0.28194432755311327    4.0  \n",
      "1                [chicken, yellow rice]   0.2791937967141469    4.0  \n",
      "2                       [chicken, salt]   0.2768626441558202    3.0  \n",
      "3                    [chicken, ketchup]   0.2743554939826329    4.0  \n",
      "4             [barbecue sauce, chicken]   0.2691343208154042    4.0  \n",
      "5         [butter, chicken, white rice]  0.26246511127267563    4.0  \n",
      "6            [chicken, spaghetti sauce]  0.26076471110184984   4.33  \n",
      "7    [chicken, chicken gravy, mushroom]  0.25493692542825425   4.83  \n",
      "8         [beer, chicken, lemon pepper]   0.2530475475958415   4.75  \n",
      "9  [brown rice, butter, chicken, water]  0.24918866753578187    5.0  \n"
     ]
    }
   ],
   "source": [
    "#Cosine_weight of 0.2\n",
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "combined_similar = get_recs(input_ingredient, cosine_weight = 0.2, N = 10)\n",
    "print(combined_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1497e633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              recipe  \\\n",
      "0            Nif's Butterflied Grilled Whole Chicken   \n",
      "1    Too Tired, &amp; Broke, Yellow Rice and Chicken   \n",
      "2                      Easiest Chicken Recipe of All   \n",
      "3                          Amanda's Chicken and Rice   \n",
      "4                  The Easiest Chicken in the World!   \n",
      "5  Chicken or Beef Flavored Brown Rice Using Pamp...   \n",
      "6                           Rick's Crock Pot Chicken   \n",
      "7                             Barbecued Oven Chicken   \n",
      "8                              Beerinthebutt chicken   \n",
      "9   Buffalo Chicken Deviled Eggs (Aka Buffalo Horns)   \n",
      "\n",
      "                                         ingredients                score  \\\n",
      "0                      [chicken, dry rub seasonings]  0.45486082633336383   \n",
      "1                             [chicken, yellow rice]   0.4479844768842061   \n",
      "2                                    [chicken, salt]   0.4421566029389699   \n",
      "3                      [butter, chicken, white rice]    0.441877041544233   \n",
      "4                                 [chicken, ketchup]  0.43588872750600177   \n",
      "5               [brown rice, butter, chicken, water]  0.43547165393829346   \n",
      "6                 [chicken, chicken gravy, mushroom]  0.42305657693317955   \n",
      "7                          [barbecue sauce, chicken]  0.42283578713734943   \n",
      "8                      [beer, chicken, lemon pepper]  0.41833314725330895   \n",
      "9  [butter, celery, chicken, cooked chicken, hard...   0.4163594126701355   \n",
      "\n",
      "  rating  \n",
      "0    4.0  \n",
      "1    4.0  \n",
      "2    3.0  \n",
      "3    4.0  \n",
      "4    4.0  \n",
      "5    5.0  \n",
      "6   4.83  \n",
      "7    4.0  \n",
      "8   4.75  \n",
      "9    5.0  \n"
     ]
    }
   ],
   "source": [
    "#Cosine weight of 0.5\n",
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "combined_similar = get_recs(input_ingredient, N=10, cosine_weight = 0.5)\n",
    "print(combined_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64ce0878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              recipe  \\\n",
      "0            Nif's Butterflied Grilled Whole Chicken   \n",
      "1  Chicken or Beef Flavored Brown Rice Using Pamp...   \n",
      "2                          Amanda's Chicken and Rice   \n",
      "3    Too Tired, &amp; Broke, Yellow Rice and Chicken   \n",
      "4                      Easiest Chicken Recipe of All   \n",
      "5   Buffalo Chicken Deviled Eggs (Aka Buffalo Horns)   \n",
      "6                  The Easiest Chicken in the World!   \n",
      "7                                     Phoney Abalone   \n",
      "8  All Purpose Chicken &amp; Broth from the Crock...   \n",
      "9                           Rick's Crock Pot Chicken   \n",
      "\n",
      "                                         ingredients               score  \\\n",
      "0                      [chicken, dry rub seasonings]  0.6277773102124532   \n",
      "1               [brown rice, butter, chicken, water]  0.6217546701431275   \n",
      "2                      [butter, chicken, white rice]   0.621289016519274   \n",
      "3                             [chicken, yellow rice]  0.6167751868565877   \n",
      "4                                    [chicken, salt]  0.6074505766232808   \n",
      "5  [butter, celery, chicken, cooked chicken, hard...  0.6061750841140747   \n",
      "6                                 [chicken, ketchup]  0.5974219759305318   \n",
      "7  [chicken, chicken breasts, cracker crumbs, egg...  0.5919132423400879   \n",
      "8  [carrot, celery rib, chicken, chicken broth, o...  0.5912470830811395   \n",
      "9                 [chicken, chicken gravy, mushroom]  0.5911762731415885   \n",
      "\n",
      "  rating  \n",
      "0    4.0  \n",
      "1    5.0  \n",
      "2    4.0  \n",
      "3    4.0  \n",
      "4    3.0  \n",
      "5    5.0  \n",
      "6    4.0  \n",
      "7    5.0  \n",
      "8   3.44  \n",
      "9   4.83  \n"
     ]
    }
   ],
   "source": [
    "#Cosine weight of 0.8\n",
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "combined_similar = get_recs(input_ingredient, cosine_weight = 0.8, N = 10)\n",
    "print(combined_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b77c9",
   "metadata": {},
   "source": [
    "# Initial Model Iteration\n",
    "With the following parameters (sg = 0, workers = 3, min_count = 1, window = 9, vector_size = 100), the model produced good results with cosine similarity, but horrible results for jaccard similarity. Our goal for the project is to produce recipes that have same ingredients and produce a grocery list of ingredients from those recipes.Even with a good cosine similarity result, the recipes produced were very simple and plain recipes. \n",
    "\n",
    "Since GridSearchCV doesn't work with Word2Vec, we need to manually try other hyperparameters to see if the outcomes from the new model will provide better results. The hyperparameters I believe that we won't need to change as it won't make a drastic change to the results are\n",
    "- sg as we want to use only CBOW model\n",
    "- workers, we are going to leave it as default\n",
    "- min_count as we want all ingredients to have an embedding\n",
    "- window we want to set as the average length of all documents.\n",
    "\n",
    "The only hyperparameter that we can adjust and may see different results is the vector size. The vector size refers to the dimensionality and determine whether general word or specific nuanced relationship between words will affect the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a91218",
   "metadata": {},
   "source": [
    "# 2nd Iteration with vec size 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c63ec769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Word2Vec model with vec size of 50\n",
    "total_lengths = [len(ingredients) for ingredients in df['ingredients']]\n",
    "avg_len = sum(total_lengths) / len(total_lengths)\n",
    "\n",
    "model_Word2Vec = Word2Vec(ingredients_corpus, \n",
    "                          sg = 0, \n",
    "                          workers = 3, \n",
    "                          min_count = 1, \n",
    "                          window = avg_len, \n",
    "                          vector_size = 50)\n",
    "\n",
    "w2v = {word: model_Word2Vec.wv[word] for word in model_Word2Vec.wv.key_to_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b58bc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Recommendation\n",
    "def get_recommendations(N, scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\",\"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "def get_recs_cosine_2(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    \"\"\"\n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df\n",
    "    # create corpus\n",
    "    corpus = get_and_sort_corpus(data)\n",
    "\n",
    "    # get average embdeddings for each document\n",
    "    mean_vec_tr = MeanEmbeddingVectorizer(model_Word2Vec)\n",
    "    doc_vec = mean_vec_tr.transform(corpus)\n",
    "    doc_vec = [doc.reshape(1, -1) for doc in doc_vec]\n",
    "    assert len(doc_vec) == len(corpus)\n",
    "    \n",
    "\n",
    "    # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input = ingredient_preprocess(input)\n",
    "    # get embeddings for ingredient doc\n",
    "    input_embedding = mean_vec_tr.transform([input])[0].reshape(1, -1)\n",
    "   \n",
    "    # get cosine similarity between input embedding and all the document embeddings\n",
    "    cos_sim = map(lambda x: cosine_similarity(input_embedding, x)[0][0], doc_vec)\n",
    "    scores = list(cos_sim)\n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c22bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              recipe  \\\n",
      "0                          Amanda's Chicken and Rice   \n",
      "1  Chicken or Beef Flavored Brown Rice Using Pamp...   \n",
      "2            Nif's Butterflied Grilled Whole Chicken   \n",
      "3   Buffalo Chicken Deviled Eggs (Aka Buffalo Horns)   \n",
      "4                             No Noodle Chicken Soup   \n",
      "5                                         Cup A Rice   \n",
      "6                    Crock Pot Chicken With Potatoes   \n",
      "7                                     Phoney Abalone   \n",
      "8              Quick Chicken, Rice &amp; Veggie Soup   \n",
      "9  All Purpose Chicken &amp; Broth from the Crock...   \n",
      "\n",
      "                                         ingredients               score  \\\n",
      "0                      [butter, chicken, white rice]   0.759509265422821   \n",
      "1               [brown rice, butter, chicken, water]  0.7584822773933411   \n",
      "2                      [chicken, dry rub seasonings]  0.7480008602142334   \n",
      "3  [butter, celery, chicken, cooked chicken, hard...  0.7480000257492065   \n",
      "4           [carrot, chicken breasts, chicken broth]  0.7309310436248779   \n",
      "5  [chicken breasts, cooked rice, cream of chicke...  0.7296399474143982   \n",
      "6  [chicken breasts, cream of chicken soup, onion...  0.7231190204620361   \n",
      "7  [chicken, chicken breasts, cracker crumbs, egg...   0.721911609172821   \n",
      "8  [butter, carrot, celery, chicken, chicken, chi...  0.7153902649879456   \n",
      "9  [carrot, celery rib, chicken, chicken broth, o...  0.7142133712768555   \n",
      "\n",
      "  rating  \n",
      "0    4.0  \n",
      "1    5.0  \n",
      "2    4.0  \n",
      "3    5.0  \n",
      "4    5.0  \n",
      "5   4.33  \n",
      "6    5.0  \n",
      "7    5.0  \n",
      "8    4.5  \n",
      "9   3.44  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "rec_cosine_2 = get_recs_cosine_2(input_ingredient, N=10)\n",
    "print(rec_cosine_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "344afb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(N, scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\", \"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def get_recs_jaccard_2(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    \"\"\"\n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df[df['n_ingredients'] >5]\n",
    "    \n",
    "     # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input_ingredient = ingredient_preprocess(input)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        intersection = len(set(input_ingredient).intersection(set(row['ingredients'])))\n",
    "        union = len(set(input_ingredient).union(set(row['ingredients'])))\n",
    "        jaccard_similarity = intersection / union\n",
    "        scores.append(jaccard_similarity)\n",
    "        \n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a33439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   recipe  \\\n",
      "0                   Lemon-Buttered Salmon   \n",
      "1                   Lemony Salmon Patties   \n",
      "2                        Shepherd's Pie V   \n",
      "3                        Spicy Fish Cakes   \n",
      "4                          Karo Pecan Pie   \n",
      "5                Puffy Parmesan Pinwheels   \n",
      "6                     Ricotta Spinach Pie   \n",
      "7  Baked Chicken with Garlic and Rosemary   \n",
      "8                Aussie Tuna Summer Salad   \n",
      "9      Baked Brie with Caramelized Pecans   \n",
      "\n",
      "                                         ingredients score rating  \n",
      "0  [butter, herb seasoned salt, lemon juice, papr...   0.1    4.6  \n",
      "1  [all purpose flour, butter, cayenne pepper, eg...   0.1   4.42  \n",
      "2  [beef, cream style corn, mashed potatoes, onio...   0.1    4.5  \n",
      "3  [butter, creole seasoning, egg, fish fillets, ...   0.1    3.0  \n",
      "4  [butter, dark karo syrup, egg, pecan, salt, su...   0.1    4.0  \n",
      "5  [black olives, hungarian paprika, parmesan che...   0.1    5.0  \n",
      "6  [butter, butter, egg yolks, fresh basil, fresh...   0.1    3.0  \n",
      "7  [chicken portions, chicken stock powder, fresh...   0.1    4.5  \n",
      "8  [avocado, balsamic vinegar, basil, button mush...   0.1    4.6  \n",
      "9  [brie cheese, brown sugar, butter, pecan, sour...   0.1    2.5  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "rec_jaccard_2 = get_recs_jaccard_2(input_ingredient, N=10)\n",
    "print(rec_jaccard_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc405a9",
   "metadata": {},
   "source": [
    "## 2nd Iteration Conclusion\n",
    "We can see the cosine scores for the recipes increased drastically for the top recipes up from approximtaley 77% to 90%. For the Jaccard scores, they remain the same at 0.1.\n",
    "\n",
    "The cosine recommendation have a few of the same recipes as the first interation, but ranked differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f038db2",
   "metadata": {},
   "source": [
    "# 3rd Iteration with vec size 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62140626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Word2Vec model with vec size of 150\n",
    "total_lengths = [len(ingredients) for ingredients in df['ingredients']]\n",
    "avg_len = sum(total_lengths) / len(total_lengths)\n",
    "\n",
    "model_Word2Vec = Word2Vec(ingredients_corpus, \n",
    "                          sg = 0, \n",
    "                          workers = 3, \n",
    "                          min_count = 1, \n",
    "                          window = avg_len, \n",
    "                          vector_size = 150)\n",
    "\n",
    "w2v = {word: model_Word2Vec.wv[word] for word in model_Word2Vec.wv.key_to_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d414e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Recommendation\n",
    "def get_recommendations(N, scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\",\"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "def get_recs_cosine_3(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    \"\"\"\n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df\n",
    "    # create corpus\n",
    "    corpus = get_and_sort_corpus(data)\n",
    "\n",
    "    # get average embdeddings for each document\n",
    "    mean_vec_tr = MeanEmbeddingVectorizer(model_Word2Vec)\n",
    "    doc_vec = mean_vec_tr.transform(corpus)\n",
    "    doc_vec = [doc.reshape(1, -1) for doc in doc_vec]\n",
    "    assert len(doc_vec) == len(corpus)\n",
    "    \n",
    "\n",
    "    # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input = ingredient_preprocess(input)\n",
    "    # get embeddings for ingredient doc\n",
    "    input_embedding = mean_vec_tr.transform([input])[0].reshape(1, -1)\n",
    "   \n",
    "    # get cosine similarity between input embedding and all the document embeddings\n",
    "    cos_sim = map(lambda x: cosine_similarity(input_embedding, x)[0][0], doc_vec)\n",
    "    scores = list(cos_sim)\n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32b1d62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              recipe  \\\n",
      "0  Chicken or Beef Flavored Brown Rice Using Pamp...   \n",
      "1            Nif's Butterflied Grilled Whole Chicken   \n",
      "2                          Amanda's Chicken and Rice   \n",
      "3                                     Phoney Abalone   \n",
      "4                                         Cup A Rice   \n",
      "5                             No Noodle Chicken Soup   \n",
      "6   Buffalo Chicken Deviled Eggs (Aka Buffalo Horns)   \n",
      "7                    Crock Pot Chicken With Potatoes   \n",
      "8  All Purpose Chicken &amp; Broth from the Crock...   \n",
      "9                   Quick and Easy Blackened Chicken   \n",
      "\n",
      "                                         ingredients               score  \\\n",
      "0               [brown rice, butter, chicken, water]  0.7620192766189575   \n",
      "1                      [chicken, dry rub seasonings]   0.760386049747467   \n",
      "2                      [butter, chicken, white rice]  0.7549707889556885   \n",
      "3  [chicken, chicken breasts, cracker crumbs, egg...  0.7502956390380859   \n",
      "4  [chicken breasts, cooked rice, cream of chicke...  0.7477378845214844   \n",
      "5           [carrot, chicken breasts, chicken broth]  0.7460997104644775   \n",
      "6  [butter, celery, chicken, cooked chicken, hard...  0.7318763136863708   \n",
      "7  [chicken breasts, cream of chicken soup, onion...  0.7315217852592468   \n",
      "8  [carrot, celery rib, chicken, chicken broth, o...  0.7249923944473267   \n",
      "9  [blackened fish seasoning, boneless skinless c...  0.7225205898284912   \n",
      "\n",
      "  rating  \n",
      "0    5.0  \n",
      "1    4.0  \n",
      "2    4.0  \n",
      "3    5.0  \n",
      "4   4.33  \n",
      "5    5.0  \n",
      "6    5.0  \n",
      "7    5.0  \n",
      "8   3.44  \n",
      "9    5.0  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "rec_cosine_3 = get_recs_cosine_3(input_ingredient, N=10)\n",
    "print(rec_cosine_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fb500d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(N, scores):\n",
    "    \"\"\"\n",
    "    Rank scores and output a pandas data frame containing all the details of the top N recipes.\n",
    "    :param scores: list of cosine similarities\n",
    "    \"\"\"\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations\n",
    "    recommendation = pd.DataFrame(columns=[\"recipe\", \"ingredients\", \"score\", \"rating\"])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.loc[count, \"recipe\"] = df[\"RecipeName\"][i]\n",
    "        recommendation.loc[count, \"ingredients\"] = df[\"ingredients\"][i]\n",
    "        recommendation.loc[count, \"score\"] = f\"{scores[i]}\"\n",
    "        recommendation.loc[count, \"rating\"] = df['AggregatedRating'][i]\n",
    "        count += 1\n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def get_recs_jaccard_3(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    Get the top N recipe recomendations.\n",
    "    :param ingredients: comma seperated string listing ingredients\n",
    "    :param N: number of recommendations\n",
    "    \"\"\"\n",
    "    # load in word2vec model\n",
    "    model = model_Word2Vec\n",
    "    # normalize embeddings\n",
    "    model.init_sims(replace=True)\n",
    "    # load in data\n",
    "    data = df[df['n_ingredients'] >5]\n",
    "    \n",
    "     # create embeddings for input text\n",
    "    input = ingredients\n",
    "    # create tokens with elements\n",
    "    input = input.split(\",\")\n",
    "    # parse ingredient list\n",
    "    input_ingredient = ingredient_preprocess(input)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        intersection = len(set(input_ingredient).intersection(set(row['ingredients'])))\n",
    "        union = len(set(input_ingredient).union(set(row['ingredients'])))\n",
    "        jaccard_similarity = intersection / union\n",
    "        scores.append(jaccard_similarity)\n",
    "        \n",
    "    # Filter top N recommendations\n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d58a38b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   recipe  \\\n",
      "0                   Lemon-Buttered Salmon   \n",
      "1                   Lemony Salmon Patties   \n",
      "2                        Shepherd's Pie V   \n",
      "3                        Spicy Fish Cakes   \n",
      "4                          Karo Pecan Pie   \n",
      "5                Puffy Parmesan Pinwheels   \n",
      "6                     Ricotta Spinach Pie   \n",
      "7  Baked Chicken with Garlic and Rosemary   \n",
      "8                Aussie Tuna Summer Salad   \n",
      "9      Baked Brie with Caramelized Pecans   \n",
      "\n",
      "                                         ingredients score rating  \n",
      "0  [butter, herb seasoned salt, lemon juice, papr...   0.1    4.6  \n",
      "1  [all purpose flour, butter, cayenne pepper, eg...   0.1   4.42  \n",
      "2  [beef, cream style corn, mashed potatoes, onio...   0.1    4.5  \n",
      "3  [butter, creole seasoning, egg, fish fillets, ...   0.1    3.0  \n",
      "4  [butter, dark karo syrup, egg, pecan, salt, su...   0.1    4.0  \n",
      "5  [black olives, hungarian paprika, parmesan che...   0.1    5.0  \n",
      "6  [butter, butter, egg yolks, fresh basil, fresh...   0.1    3.0  \n",
      "7  [chicken portions, chicken stock powder, fresh...   0.1    4.5  \n",
      "8  [avocado, balsamic vinegar, basil, button mush...   0.1    4.6  \n",
      "9  [brie cheese, brown sugar, butter, pecan, sour...   0.1    2.5  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"chicken, onion, spinach, garlic, pasta\"\n",
    "rec_jaccard_3 = get_recs_jaccard_3(input_ingredient, N=10)\n",
    "print(rec_jaccard_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2bacc8",
   "metadata": {},
   "source": [
    "# Vector Size Conclusion\n",
    "Based on a the three choices for vector size (50, 100, 150), 150 attained the highest cosine similarity score while vector size of 100 attained the lowest cosine similarity score. It seems that a more general relationship between words allowed for the model to attain a better performance. As such we will use the 50 as our vector size for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438098a",
   "metadata": {},
   "source": [
    "# Test trial with Content-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cc547ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  recipe  \\\n",
      "0                Man-Style Spanish Steak   \n",
      "1                J.w.'s Quick Coq Au Vin   \n",
      "2          South African Chutney Chicken   \n",
      "3  Easy Delicious Slow Cooker Roast Beef   \n",
      "4            Sweet and Sour Cabbage Stew   \n",
      "5        Yorkshire Corned Beef Hash Soup   \n",
      "6                      Lo Sung Beef Soup   \n",
      "7              Beef and Black Bean Sauce   \n",
      "8                         Plum Pot Roast   \n",
      "9                       Chinese Stir-Fry   \n",
      "\n",
      "                                         ingredients               score  \\\n",
      "0  [bay leaf, canned tomatoes, chuck steaks, dry ...  0.8232737183570862   \n",
      "1  [beef bouillon cube, chicken, dry red wine, li...  0.8156026601791382   \n",
      "2      [chicken thighs, chutney, dry onion soup mix]  0.7985493540763855   \n",
      "3  [bay leaves, beef roast, black pepper, dry oni...  0.7871913313865662   \n",
      "4  [beef stew meat, cabbage, chili sauce, jellied...  0.7787079215049744   \n",
      "5  [bay leaves, beef stock cube, button mushrooms...  0.7775267362594604   \n",
      "6  [beef, brown onion, cabbage, carrot, cooking w...  0.7767700552940369   \n",
      "7  [bean sprouts, beef stock, black bean garlic s...  0.7749094367027283   \n",
      "8  [beef roast, beer, brown sugar, chili powder, ...  0.7740326523780823   \n",
      "9  [beef bouillon cubes, beef flank steak, brocco...  0.7666642665863037   \n",
      "\n",
      "  rating  \n",
      "0    4.6  \n",
      "1    4.0  \n",
      "2    5.0  \n",
      "3   4.68  \n",
      "4   4.67  \n",
      "5   4.67  \n",
      "6    4.6  \n",
      "7   4.17  \n",
      "8    3.5  \n",
      "9    5.0  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"beef, potato, rice, pepper\"\n",
    "rec_cosine_3 = get_recs_cosine_3(input_ingredient, N=10)\n",
    "print(rec_cosine_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a99cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            recipe  \\\n",
      "0                                 Lao Papaya Salad   \n",
      "1            Thai Catfish Salad (Yam Pla Dook Foo)   \n",
      "2  Delicious Indian Spicy Chicken Sandwich Filling   \n",
      "3                  Vietnamese Chicken Lettuce Cups   \n",
      "4           Ohn-No-Kauk-Swe (Burmese Chicken Soup)   \n",
      "5                                Aussie Rice Salad   \n",
      "6                 Chez's Apricot and Mango Chicken   \n",
      "7       Indonesian Chicken Noodle Soup (Soto Ayam)   \n",
      "8                                            Laksa   \n",
      "9                  Creamy Garlicy Seafood Marinara   \n",
      "\n",
      "                                         ingredients               score  \\\n",
      "0  [cherry tomatoes, chilies, crab, fish, fish sa...  0.8127458095550537   \n",
      "1  [birds eye chiles, breadcrumb, brown sugar, ca...  0.7886019349098206   \n",
      "2  [chestnut, chicken breast, chicken stock powde...  0.7845373749732971   \n",
      "3  [carrot, chicken, chili, iceberg lettuce, mint...  0.7814772129058838   \n",
      "4  [boiling water, boiling water, chicken stock, ...  0.7666024565696716   \n",
      "5  [allspice, bacos bacon bits, canned corn, cook...  0.7623316049575806   \n",
      "6  [apricot jam, chicken thigh fillets, cream, ke...  0.7618732452392578   \n",
      "7  [bean sprouts, black peppercorns, candlenut, c...   0.761721134185791   \n",
      "8  [bean sprouts, candlenut, chicken, chicken fil...   0.761693000793457   \n",
      "9  [broccoli floret, carrot, cauliflower floret, ...  0.7570087313652039   \n",
      "\n",
      "  rating  \n",
      "0    4.0  \n",
      "1    5.0  \n",
      "2    5.0  \n",
      "3    1.5  \n",
      "4   4.78  \n",
      "5   4.87  \n",
      "6    3.8  \n",
      "7    5.0  \n",
      "8    5.0  \n",
      "9    5.0  \n"
     ]
    }
   ],
   "source": [
    "input_ingredient = \"fish, carrot, rice, celery\"\n",
    "rec_cosine_3 = get_recs_cosine_3(input_ingredient, N=10)\n",
    "print(rec_cosine_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ee2f0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Using Jaccard similarity score does not produce any good results for our recommendation as all the scores are very low. The low scores are indicating that not a lot of recipes contain the same ingredients as the input ingredients. Even when using a hybrid score of Jaccard and Cosine, when the Jaccard socre weight increases, the overall score decreases. Given that our initial goal of recommending a list of recipes with the same ingredients but differing taste, our model using the jaccard score is not doing a good job. We will need to dropthe jaccard similarity score in our content-based recommender system and just use the cosine similarity score. \n",
    "\n",
    "Our cosine recommender system runs with with multiple different input ingredients receiving cosine scores between 70% to 80%.\n",
    "\n",
    "Recapping on our conclusion, we will be using the following hyperparameters for our Word2Vec model for the most optimized cosine similarity score:  sg = 0, workers = 3, min_count = 1, window = average length of document in corpuse, vector_size = 50. \n",
    "\n",
    "The downside of how our content-based recommender system is that it doesn't take into account of the history of the user's like. We may be recommending certain items that although has a high cosine similarity score, may not be liked by the user. One way we can solve this is to combine both the content-based recommender and collaborative recommender, which will be discussed in the hybrid model notebook.\n",
    "\n",
    "The pros of using the content-based recommender system is that it can capture specific recipes that the user inputs, which the collaborative model does not do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967132b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
